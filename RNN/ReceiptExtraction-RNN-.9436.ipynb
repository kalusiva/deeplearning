{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "# this finds our json files\n",
    "path_to_json = 'CORD/train/json/'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "\n",
    "# here I define my pandas Dataframe with the columns I want to get from the json\n",
    "jsons_data = pd.DataFrame(columns=['validline'])\n",
    "\n",
    "f = open(\"receipt_words.csv\", \"w\")\n",
    "print(\"filename\",\",\",\"index\",\",\",\"x1\",\",\",'x2',\",\",'x3',\",\",'x4',\",\",'y1',\",\",'y2',\",\",'y3',\",\",'y4',\",\",'is_key',\",\",'row_id',\",\",'text',\",\",'category',\",\",\"group_id\",file=f)\n",
    "\n",
    "\n",
    "# we need both the json and an index number so use enumerate()\n",
    "for index, js in enumerate(json_files):\n",
    "    with open(os.path.join(path_to_json, js)) as json_file:\n",
    "        json_text = json.load(json_file)\n",
    "        \n",
    "       # print(json_text)\n",
    "\n",
    "        # here you need to know the layout of your json and each json has to have\n",
    "        # the same structure (obviously not the structure I have here)\n",
    "        lines = json_text['valid_line']\n",
    "        \n",
    "        for x in lines:\n",
    "            words = x['words']\n",
    "            category = x['category']\n",
    "            group_id = x['group_id']\n",
    "            for y in words:\n",
    "                print(js,index,y['quad']['x1'],y['quad']['x2'],y['quad']['x3'],y['quad']['x4'],y['quad']['y1'],y['quad']['y2'],y['quad']['y3'],y['quad']['y4'],y['is_key'],y['row_id'],\"\\\"\"+y['text']+\"\\\"\",category,group_id,file=f,sep=\",\")\n",
    "\n",
    "       # city = json_text['features'][0]['properties']['name']\n",
    "        #lonlat = json_text['features'][0]['geometry']['coordinates']\n",
    "        # here I push a list of data into a pandas DataFrame at row given by 'index'\n",
    "        #f.close()\n",
    "        #jsons_data.loc[index] = [words, city, lonlat]\n",
    "\n",
    "# now that we have the pertinent json data in our DataFrame let's look at it\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "receipts_df = pd.read_csv(\"receipt_words.csv\")\n",
    "receipts_df.columns = receipts_df.columns.str.strip()\n",
    "receipts_df['text'] = receipts_df['text'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename    object\n",
       "index        int64\n",
       "x1           int64\n",
       "x2           int64\n",
       "x3           int64\n",
       "x4           int64\n",
       "y1           int64\n",
       "y2           int64\n",
       "y3           int64\n",
       "y4           int64\n",
       "is_key       int64\n",
       "row_id       int64\n",
       "text        object\n",
       "category    object\n",
       "group_id     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipts_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {\"START\":0,\"END\":1,\"a\":2,\"b\":3,\"c\":4,\"d\":5,\"e\":6,\"f\":7,\"g\":8,\"h\":9,\"i\":10,\"j\":11,\"k\":12,\"l\":13,\"m\":14,\"n\":15,\"o\":16,\"p\":17,\"q\":18,\"r\":19,\"s\":20,\"t\":21,\"u\":22,\"v\":23,\"w\":24,\"x\":25,\"y\":26,\"z\":27,\"0\":28,\"1\":29,\"2\":30,\"3\":31,\"4\":32,\"5\":33,\"6\":34,\"7\":35,\"8\":36,\"9\":37,\".\":38,\"-\":39,\",\":40,\":\":41,\" \":42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename    object\n",
       "index        int64\n",
       "x1           int64\n",
       "x2           int64\n",
       "x3           int64\n",
       "x4           int64\n",
       "y1           int64\n",
       "y2           int64\n",
       "y3           int64\n",
       "y4           int64\n",
       "is_key       int64\n",
       "row_id       int64\n",
       "text        object\n",
       "category    object\n",
       "group_id     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p_test.SentimentText=p_test.SentimentText.astype(str)\n",
    "receipts_df.text = receipts_df.text.astype(str)\n",
    "receipts_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = receipts_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_words = []\n",
    "j=43\n",
    "for word in words:\n",
    "    indexed_word = []\n",
    "    #print(word)\n",
    "    word = word.lower();\n",
    "    for i in range(len(word)):\n",
    "        token = word[i]\n",
    "        if token not in char2idx:\n",
    "            char2idx[token] = j\n",
    "            j += 1\n",
    "        indexed_word.append(char2idx[token])\n",
    "    indexed_words.append(indexed_word)\n",
    "\n",
    "receipts_df[\"indexed_words\"] = indexed_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_bigram_probs(words, V, start_idx, end_idx, smoothing=1):\n",
    "  # structure of bigram probability matrix will be:\n",
    "  # (last word, current word) --> probability\n",
    "  # we will use add-1 smoothing\n",
    "  # note: we'll always ignore this from the END token\n",
    "  bigram_probs = np.ones((V, V)) * smoothing\n",
    "  for word in words:\n",
    "    for i in range(len(word)):\n",
    "      \n",
    "      if i == 0:\n",
    "        # beginning word\n",
    "        word[i]\n",
    "        bigram_probs[start_idx, word[i]] += 1\n",
    "      else:\n",
    "        # middle word\n",
    "        bigram_probs[word[i-1], word[i]] += 1\n",
    "\n",
    "      # if we're at the final word\n",
    "      # we update the bigram for last -> current\n",
    "      # AND current -> END token\n",
    "      if i == len(word) - 1:\n",
    "        # final word\n",
    "        bigram_probs[word[i], end_idx] += 1\n",
    "\n",
    "  # normalize the counts along the rows to get probabilities\n",
    "  bigram_probs /= bigram_probs.sum(axis=1, keepdims=True)\n",
    "  return bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = char2idx['START']\n",
    "end_idx = char2idx['END']\n",
    "V = len(char2idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_probs = get_bigram_probs(indexed_words, V, start_idx, end_idx, smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.27303790e-06, 5.27303790e-06, 1.57716564e-02, ...,\n",
       "        1.10733796e-04, 5.80034169e-05, 1.10733796e-04],\n",
       "       [1.56250000e-02, 1.56250000e-02, 1.56250000e-02, ...,\n",
       "        1.56250000e-02, 1.56250000e-02, 1.56250000e-02],\n",
       "       [1.57918009e-05, 7.97643863e-02, 8.05381846e-04, ...,\n",
       "        1.57918009e-05, 1.57918009e-05, 1.57918009e-05],\n",
       "       ...,\n",
       "       [1.19047619e-02, 2.50000000e-01, 1.19047619e-02, ...,\n",
       "        1.19047619e-02, 1.19047619e-02, 1.19047619e-02],\n",
       "       [1.19047619e-02, 1.19047619e-02, 1.19047619e-02, ...,\n",
       "        1.19047619e-02, 1.30952381e-01, 1.19047619e-02],\n",
       "       [1.19047619e-02, 1.19047619e-02, 1.30952381e-01, ...,\n",
       "        1.19047619e-02, 1.19047619e-02, 1.19047619e-02]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # a function to calculate normalized log prob score\n",
    "  # for a sentence\n",
    "def get_score(word):\n",
    "    #print(\"word\")\n",
    "    #print(word)\n",
    "    score = 0\n",
    "    if len(word) > 0 :\n",
    "        for i in range(len(word)):\n",
    "          if i == 0:\n",
    "            # beginning word\n",
    "            score += np.log(bigram_probs[start_idx, word[i]])\n",
    "          else:\n",
    "            # middle word\n",
    "            score += np.log(bigram_probs[word[i-1], word[i]])\n",
    "        # final word\n",
    "        score += np.log(bigram_probs[word[i-1], end_idx])\n",
    "\n",
    "    # normalize the score\n",
    "    # return score / (len(word) + 1)\n",
    "    if score == 0:\n",
    "        return score;\n",
    "    else :\n",
    "        return  ((-1)*(len(word) + 1)/score)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.utils import iteritems\n",
    "\n",
    "idx2char = dict((v, k) for k, v in iteritems(char2idx))\n",
    "def get_word(word):\n",
    "    return ''.join(idx2char[i] for i in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts_df['text_score'] = receipts_df.apply(lambda row : get_score(row['indexed_words']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>index</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>is_key</th>\n",
       "      <th>row_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>group_id</th>\n",
       "      <th>indexed_words</th>\n",
       "      <th>text_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>receipt_00580.json</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>325</td>\n",
       "      <td>325</td>\n",
       "      <td>250</td>\n",
       "      <td>833</td>\n",
       "      <td>834</td>\n",
       "      <td>869</td>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>879802</td>\n",
       "      <td>Tebu</td>\n",
       "      <td>menu.nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[21, 6, 3, 22]</td>\n",
       "      <td>36.669749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>receipt_00580.json</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>434</td>\n",
       "      <td>433</td>\n",
       "      <td>339</td>\n",
       "      <td>832</td>\n",
       "      <td>833</td>\n",
       "      <td>868</td>\n",
       "      <td>867</td>\n",
       "      <td>0</td>\n",
       "      <td>879802</td>\n",
       "      <td>Lemon</td>\n",
       "      <td>menu.nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[13, 6, 14, 16, 15]</td>\n",
       "      <td>35.199925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>receipt_00580.json</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>217</td>\n",
       "      <td>835</td>\n",
       "      <td>834</td>\n",
       "      <td>869</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>879802</td>\n",
       "      <td>1</td>\n",
       "      <td>menu.cnt</td>\n",
       "      <td>3</td>\n",
       "      <td>[29]</td>\n",
       "      <td>75.625303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>receipt_00580.json</td>\n",
       "      <td>0</td>\n",
       "      <td>841</td>\n",
       "      <td>954</td>\n",
       "      <td>954</td>\n",
       "      <td>841</td>\n",
       "      <td>824</td>\n",
       "      <td>824</td>\n",
       "      <td>864</td>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>879802</td>\n",
       "      <td>22.000</td>\n",
       "      <td>menu.price</td>\n",
       "      <td>3</td>\n",
       "      <td>[30, 30, 38, 28, 28, 28]</td>\n",
       "      <td>66.930682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receipt_00580.json</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>342</td>\n",
       "      <td>344</td>\n",
       "      <td>249</td>\n",
       "      <td>921</td>\n",
       "      <td>920</td>\n",
       "      <td>990</td>\n",
       "      <td>992</td>\n",
       "      <td>1</td>\n",
       "      <td>879803</td>\n",
       "      <td>Total</td>\n",
       "      <td>total.total_price</td>\n",
       "      <td>4</td>\n",
       "      <td>[21, 16, 21, 2, 13]</td>\n",
       "      <td>62.899046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18953</th>\n",
       "      <td>receipt_00281.json</td>\n",
       "      <td>786</td>\n",
       "      <td>186</td>\n",
       "      <td>449</td>\n",
       "      <td>451</td>\n",
       "      <td>188</td>\n",
       "      <td>671</td>\n",
       "      <td>654</td>\n",
       "      <td>691</td>\n",
       "      <td>707</td>\n",
       "      <td>1</td>\n",
       "      <td>1623131</td>\n",
       "      <td>SUBTOTAL</td>\n",
       "      <td>sub_total.subtotal_price</td>\n",
       "      <td>10</td>\n",
       "      <td>[20, 22, 3, 21, 16, 21, 2, 13]</td>\n",
       "      <td>61.298959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18954</th>\n",
       "      <td>receipt_00281.json</td>\n",
       "      <td>786</td>\n",
       "      <td>630</td>\n",
       "      <td>712</td>\n",
       "      <td>712</td>\n",
       "      <td>630</td>\n",
       "      <td>642</td>\n",
       "      <td>642</td>\n",
       "      <td>678</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>1623131</td>\n",
       "      <td>9,500</td>\n",
       "      <td>sub_total.subtotal_price</td>\n",
       "      <td>10</td>\n",
       "      <td>[37, 40, 33, 28, 28]</td>\n",
       "      <td>54.478680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18955</th>\n",
       "      <td>receipt_00281.json</td>\n",
       "      <td>786</td>\n",
       "      <td>188</td>\n",
       "      <td>242</td>\n",
       "      <td>242</td>\n",
       "      <td>188</td>\n",
       "      <td>714</td>\n",
       "      <td>714</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>1623132</td>\n",
       "      <td>TAX</td>\n",
       "      <td>sub_total.tax_price</td>\n",
       "      <td>10</td>\n",
       "      <td>[21, 2, 25]</td>\n",
       "      <td>40.665969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18956</th>\n",
       "      <td>receipt_00281.json</td>\n",
       "      <td>786</td>\n",
       "      <td>258</td>\n",
       "      <td>310</td>\n",
       "      <td>310</td>\n",
       "      <td>258</td>\n",
       "      <td>708</td>\n",
       "      <td>708</td>\n",
       "      <td>744</td>\n",
       "      <td>744</td>\n",
       "      <td>1</td>\n",
       "      <td>1623132</td>\n",
       "      <td>10%</td>\n",
       "      <td>sub_total.tax_price</td>\n",
       "      <td>10</td>\n",
       "      <td>[29, 28, 43]</td>\n",
       "      <td>43.846155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18957</th>\n",
       "      <td>receipt_00281.json</td>\n",
       "      <td>786</td>\n",
       "      <td>664</td>\n",
       "      <td>716</td>\n",
       "      <td>716</td>\n",
       "      <td>664</td>\n",
       "      <td>684</td>\n",
       "      <td>684</td>\n",
       "      <td>718</td>\n",
       "      <td>718</td>\n",
       "      <td>0</td>\n",
       "      <td>1623132</td>\n",
       "      <td>950</td>\n",
       "      <td>sub_total.tax_price</td>\n",
       "      <td>10</td>\n",
       "      <td>[37, 33, 28]</td>\n",
       "      <td>36.356025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18958 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename  index   x1   x2   x3   x4   y1   y2   y3   y4  \\\n",
       "0      receipt_00580.json      0  250  325  325  250  833  834  869  868   \n",
       "1      receipt_00580.json      0  340  434  433  339  832  833  868  867   \n",
       "2      receipt_00580.json      0  217  227  228  217  835  834  869  869   \n",
       "3      receipt_00580.json      0  841  954  954  841  824  824  864  864   \n",
       "4      receipt_00580.json      0  249  342  344  249  921  920  990  992   \n",
       "...                   ...    ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "18953  receipt_00281.json    786  186  449  451  188  671  654  691  707   \n",
       "18954  receipt_00281.json    786  630  712  712  630  642  642  678  678   \n",
       "18955  receipt_00281.json    786  188  242  242  188  714  714  750  750   \n",
       "18956  receipt_00281.json    786  258  310  310  258  708  708  744  744   \n",
       "18957  receipt_00281.json    786  664  716  716  664  684  684  718  718   \n",
       "\n",
       "       is_key   row_id      text                  category  group_id  \\\n",
       "0           0   879802      Tebu                   menu.nm         3   \n",
       "1           0   879802     Lemon                   menu.nm         3   \n",
       "2           0   879802         1                  menu.cnt         3   \n",
       "3           0   879802    22.000                menu.price         3   \n",
       "4           1   879803     Total         total.total_price         4   \n",
       "...       ...      ...       ...                       ...       ...   \n",
       "18953       1  1623131  SUBTOTAL  sub_total.subtotal_price        10   \n",
       "18954       0  1623131     9,500  sub_total.subtotal_price        10   \n",
       "18955       1  1623132       TAX       sub_total.tax_price        10   \n",
       "18956       1  1623132       10%       sub_total.tax_price        10   \n",
       "18957       0  1623132       950       sub_total.tax_price        10   \n",
       "\n",
       "                        indexed_words  text_score  \n",
       "0                      [21, 6, 3, 22]   36.669749  \n",
       "1                 [13, 6, 14, 16, 15]   35.199925  \n",
       "2                                [29]   75.625303  \n",
       "3            [30, 30, 38, 28, 28, 28]   66.930682  \n",
       "4                 [21, 16, 21, 2, 13]   62.899046  \n",
       "...                               ...         ...  \n",
       "18953  [20, 22, 3, 21, 16, 21, 2, 13]   61.298959  \n",
       "18954            [37, 40, 33, 28, 28]   54.478680  \n",
       "18955                     [21, 2, 25]   40.665969  \n",
       "18956                    [29, 28, 43]   43.846155  \n",
       "18957                    [37, 33, 28]   36.356025  \n",
       "\n",
       "[18958 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = receipts_df['category'] \n",
    "category2idx = {}\n",
    "idx2category = {}\n",
    "j=0;\n",
    "for category in categories:\n",
    "    if category not in category2idx:\n",
    "        category2idx[category] = j\n",
    "        idx2category[j] = category\n",
    "        j+=1\n",
    "\n",
    "category2idx\n",
    "\n",
    "def get_index_for_category(category):\n",
    "    return category2idx[category]\n",
    "\n",
    "\n",
    "def get_category_for_index(index):\n",
    "    return idx2category[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'menu.nm': 0,\n",
       " 'menu.cnt': 1,\n",
       " 'menu.price': 2,\n",
       " 'total.total_price': 3,\n",
       " 'total.cashprice': 4,\n",
       " 'total.menuqty_cnt': 5,\n",
       " 'menu.unitprice': 6,\n",
       " 'sub_total.subtotal_price': 7,\n",
       " 'total.changeprice': 8,\n",
       " 'total.emoneyprice': 9,\n",
       " 'sub_total.tax_price': 10,\n",
       " 'total.creditcardprice': 11,\n",
       " 'menu.sub_nm': 12,\n",
       " 'menu.sub_price': 13,\n",
       " 'menu.discountprice': 14,\n",
       " 'sub_total.discount_price': 15,\n",
       " 'sub_total.service_price': 16,\n",
       " 'total.menutype_cnt': 17,\n",
       " 'total.total_etc': 18,\n",
       " 'sub_total.etc': 19,\n",
       " 'menu.sub_cnt': 20,\n",
       " 'menu.sub_unitprice': 21,\n",
       " 'menu.num': 22,\n",
       " 'menu.vatyn': 23,\n",
       " 'menu.sub_etc': 24,\n",
       " 'menu.itemsubtotal': 25,\n",
       " 'void_menu.nm': 26,\n",
       " 'void_menu.price': 27,\n",
       " 'menu.etc': 28,\n",
       " 'sub_total.othersvc_price': 29}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipts_df['category_idx'] = receipts_df.apply(lambda row : get_index_for_category(row['category']), axis = 1)\n",
    "category2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = receipts_df[['row_id','text_score','category_idx','index']].sort_values([\"index\", \"row_id\"], ascending = (True, True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18958, 4)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = []\n",
    "Y_1 = []\n",
    "tmp_feature = []\n",
    "tmp_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevIndx = -1;\n",
    "for ind in data_1.index: \n",
    "    #print (data_1['index'][ind])\n",
    "    #print (prevIndx)\n",
    "    if ( data_1['index'][ind] != prevIndx):\n",
    "        prevIndx = data_1['index'][ind]\n",
    "        tmp_feature = []\n",
    "        tmp_output = []\n",
    "        if(prevIndx !=  -1):\n",
    "            X_1.append(tmp_feature)\n",
    "            Y_1.append(tmp_output)\n",
    "    tmp_feature.append(data_1['text_score'][ind])\n",
    "    tmp_output.append(data_1['text_score'][ind])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sentences have disparate input-output lengths.\n"
     ]
    }
   ],
   "source": [
    "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_1, Y_1)]\n",
    "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest sentence: 135\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(seq) for seq in X_1]\n",
    "print(\"Length of longest sentence: {}\".format(max(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sns.boxplot(lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_SEQ_LENGTH = max(lengths)  # sequences greater than 100 in length will be truncated\n",
    "\n",
    "X_padded = pad_sequences(X_1, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded = pad_sequences(Y_1, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574, 135)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574, 135)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_padded = to_categorical(Y_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_padded, Y_padded\n",
    "VALID_SIZE = 0.15\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_padded, Y_padded, test_size=VALID_SIZE, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1574, 135, 96)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
    "from keras.models import Model\n",
    "\n",
    "# create architecture\n",
    "VOCABULARY_SIZE = 135\n",
    "EMBEDDING_SIZE = 135\n",
    "MAX_SEQ_LENGTH = 135\n",
    "NUM_CLASSES = Y.shape[2]\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# create embedding layer - usually the first layer in text problems\n",
    "rnn_model.add(Embedding(input_dim     =  VOCABULARY_SIZE,         # vocabulary size - number of unique words in data\n",
    "                        output_dim    =  EMBEDDING_SIZE,          # length of vector with which each word is represented\n",
    "                        input_length  =  MAX_SEQ_LENGTH,          # length of input sequence\n",
    "                        trainable     =  False                    # False - don't update the embeddings\n",
    "))\n",
    "\n",
    "# add an RNN layer which contains 64 RNN cells\n",
    "rnn_model.add(SimpleRNN(64, \n",
    "              return_sequences=True  # True - return whole sequence; False - return single output of the end of the sequence\n",
    "))\n",
    "\n",
    "# add time distributed (output at each sequence) layer\n",
    "rnn_model.add(TimeDistributed(Dense(NUM_CLASSES, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 135, 135)          18225     \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 135, 64)           12800     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 135, 96)           6240      \n",
      "=================================================================\n",
      "Total params: 37,265\n",
      "Trainable params: 19,040\n",
      "Non-trainable params: 18,225\n",
      "_________________________________________________________________\n",
      "Train on 1337 samples, validate on 237 samples\n",
      "Epoch 1/10\n",
      "1337/1337 [==============================] - 12s 9ms/step - loss: 0.8818 - acc: 0.8220 - val_loss: 0.7702 - val_acc: 0.8302\n",
      "Epoch 2/10\n",
      " 224/1337 [====>.........................] - ETA: 7s - loss: 0.8230 - acc: 0.8180"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(loss      =  'categorical_crossentropy',\n",
    "                  optimizer =  'adam',\n",
    "                  metrics   =  ['acc'])\n",
    "rnn_model.summary()\n",
    "rnn_training = rnn_model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_validation, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
